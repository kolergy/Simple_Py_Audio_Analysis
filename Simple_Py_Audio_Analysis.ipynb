{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPAA - Simple Py Audio Analysis\n",
    "\n",
    "## introduction:\n",
    "the aim of SPAA it to preform simple analysis on audio files it is strongly inspired by this article from KD Nuggets: https://www.kdnuggets.com/2020/02/audio-data-analysis-deep-learning-python-part-1.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the environement Pre requisites \n",
    "Execute the code of the following cell only once after you can coment it out and set your vscode or Jupiter to work in the SPAA environement"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environement Set-up\n",
    "Need to copy paste the text in a terminal to create the environement and install the ffmpeg if not already on your computer once done you need to set this environement on the jupyten notebook if you use it in vscode it is on the top right corner of the windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commands to execute in a terminal to have the right environement to run this\n",
    "\"\"\"\n",
    "conda deactivate\n",
    "conda env remove -n SPAA_env\n",
    "conda create --name SPAA_env python=3.10 ipywidgets ipykernel -y\n",
    "conda activate SPAA_env\n",
    "conda install -y pyaudio\n",
    "pip install -U librosa \n",
    "pip install -U scikit-learn \n",
    "pip install numpy scipy matplotlib\n",
    "\"\"\"\n",
    "# to use with ROCKm (AMD boards) replace the torch install command by the following one (untested) \n",
    "# check this page for further install instructions: https://rocmdocs.amd.com/en/latest/ and https://docs.amd.com/bundle/ROCm-Installation-Guide-v5.4.1/page/How_to_Install_ROCm.html\n",
    "#\n",
    "# pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/rocm5.2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inport the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import wave\n",
    "import sys\n",
    "import sklearn\n",
    "import pyaudio\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import numpy             as np\n",
    "import matplotlib        as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "#import IPython.display   as ipd\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "\n",
    "print(f\"Env Name  : {sys.executable.split('/')[-3]}\")\n",
    "print(f\"Python    : {                  sys.version}\")\n",
    "print(f\"sklearn   : {         sklearn.__version__ }\")\n",
    "print(f\"pyaudio   : {         pyaudio.__version__ }\")\n",
    "print(f\"librosa   : {         librosa.__version__ }\")\n",
    "print(f\"numpy     : {              np.__version__ }\")\n",
    "print(f\"matplotlib: {             mpl.__version__ }\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify your microphone devices\n",
    "\n",
    "It shall print the device id of all available recording devices.\n",
    "\n",
    "After that it might print a large number of ALSA issues do not worry it is apparently normal and there nothing much we can do about it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the audio input devices\n",
    "p          = pyaudio.PyAudio()\n",
    "info       = p.get_host_api_info_by_index(0)\n",
    "numdevices = info.get('deviceCount')\n",
    "for i in range(0, numdevices):\n",
    "        if (p.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\n",
    "            print( \"Input Device id \", i, \" - \", p.get_device_info_by_host_api_device_index(0, i).get('name'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Set-up \n",
    "set the different parameters / variables of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Folowing are a few public domain files exemples to test the analysis you can of course use your own Wave or MP3\n",
    "#prerecorded_audio = \"bells-tibetan-daniel_simon.wav\"    # https://soundbible.com/2205-Bells-Tibetan-Large.html\n",
    "#prerecorded_audio = \"Large SUV Pass By-SoundBible.com-1354956481.wav\" # https://soundbible.com/611-Large-SUV-Pass-By.html\n",
    "#prerecorded_audio = \"airplane-takeoff_daniel_simion.wav\" # https://soundbible.com/2195-Airplane-Takeoff.html\n",
    "#prerecorded_audio = \"human-heartbeat-daniel_simon.wav\"  # https://soundbible.com/2162-Human-Heartbeat.html \n",
    "#prerecorded_audio = None                       # set this to None to record your audio\n",
    "\n",
    "t_record_s        = 15\n",
    "chunk             = 1024\n",
    "swidth            = 2 \n",
    "frames_per_buffer = 12800\n",
    "format            = pyaudio.paInt16\n",
    "channels          = 1\n",
    "sample_rate       = 48000 #44100\n",
    "#target_rate       = 16000\n",
    "device_index      = 5\n",
    "\n",
    "short_normalize   = (1.0/32768.0)\n",
    "audio_file        = 'record.wav'               # Working audio file \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(frame):\n",
    "  \"\"\"Return the RMS value of the frame content\"\"\"\n",
    "  count       = len(frame) / swidth\n",
    "  format      = \"%dh\" % (count)\n",
    "  shorts      = struct.unpack(format, frame)\n",
    "  sum_squares = 0.0\n",
    "  for sample in shorts:\n",
    "      n            = sample * short_normalize\n",
    "      sum_squares += n * n\n",
    "  rms = np.power(sum_squares / count, 0.5)\n",
    "\n",
    "  return rms * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chucnk    = int(t_record_s * sample_rate / chunk)\n",
    "p           = pyaudio.PyAudio()\n",
    "stream      = p.open(    \n",
    "   format   = format,  channels          = channels,         rate = sample_rate,\n",
    "   input    = True,    frames_per_buffer = frames_per_buffer, input_device_index=device_index)\n",
    "   \n",
    "frames = []\n",
    "print(f\"-----Now Recording for {t_record_s} s-----\")\n",
    "for i in range(0,400):\n",
    "  audio_data   = stream.read(chunk, exception_on_overflow = False)\n",
    "  rms_val      = rms(audio_data)\n",
    "  print(f\"RMS: {rms_val:5.0f}\") \n",
    "  frames.append(audio_data)\n",
    "\n",
    "print(f'-----End Recording----- Last RMS: {rms_val:6.2f} ')\n",
    "stream.stop_stream()    # Stop Audio Recording  IMPORTANT\n",
    "stream.close()          # Close Audio Recording IMPORTANT\n",
    "#print(frames)\n",
    "\n",
    "wf = wave.open(wave_file, 'wb')\n",
    "wf.setnchannels(channels)\n",
    "wf.setsampwidth(p.get_sample_size(format))\n",
    "wf.setframerate(sample_rate)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream.stop_stream()    # Stop Audio Recording  IMPORTANT\n",
    "stream.close()          # Close Audio Recording IMPORTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listen to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ipd.Audio(wave_file)\n",
    "display(Audio(wave_file, autoplay=True, rate=sample_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic information about the audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x , sr         = librosa.load(wave_file, sr=None)\n",
    "n_samples      = x.shape[0]\n",
    "zero_crossings = librosa.zero_crossings(x, pad=False)\n",
    "n_zero_cross   = sum(zero_crossings)\n",
    "smpl_per_z_x   = n_samples / n_zero_cross\n",
    "num_zeroes     = n_samples - len(x.nonzero()[0])\n",
    "abs_max        = max(abs(x.max()), abs(x.min()))\n",
    "print(type(x), type(sr))#<class 'numpy.ndarray'> <class 'int'>print(x.shape, sr)#(94316,) 22050\n",
    "print(f\"shape       : {x.shape}\")\n",
    "print(f\"sample rate : {sr}\")\n",
    "print(f\"Size        : {x.nbytes/1000000} Mb\")\n",
    "print(f\"Max Value   : {x.max()}\")\n",
    "print(f\"Min Value   :{x.min()}\")\n",
    "print(f\"Max abs Val : {abs_max}\")\n",
    "print(f\"Number  of  Zeroes crossing: {n_zero_cross} z_Xings\")\n",
    "print(f\"Samples per Zeroes crossing: {smpl_per_z_x:8.2f} smpl/z_Xings\")\n",
    "print(f\"Zeroes crossing rate       : {1/(smpl_per_z_x/sr):7.1f} z_Xings/s\")\n",
    "print(f\"Zeroes      : {num_zeroes}\")\n",
    "print(f\"Zeroes      : {100 * num_zeroes / n_samples:6.2f}%\")\n",
    "print(f\"Mean        : {100 * x.mean()   / (abs_max) :7.3f}%\")\n",
    "print(len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_start    = 0.4  # fraction of the streal where the sample window starts\n",
    "window_siz = 1000  # the number of sample to display\n",
    "n0 = int(p_start * n_samples)\n",
    "n1 = n0 + window_siz\n",
    "plt.figure(figsize=(15, 6))\n",
    "librosa.display.waveshow(x, sr=sr)\n",
    "# Zooming in\n",
    "#plt.figure(figsize=(15, 6))\n",
    "#plt.plot(x[n0:n1])\n",
    "#plt.grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tutorialexample.com/understand-n_fft-hop_length-win_length-in-audio-processing-librosa-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start_s    =  1.0 * 60\n",
    "cut_len_s    =  3.0 * 60\n",
    "n_fft        = 1024\n",
    "last_s       =  len(x)\n",
    "s_start      = int(t_start_s * sr)\n",
    "n_cut        = 0\n",
    "x_cut        = []\n",
    "x_cut_fft    = []\n",
    "x_cut_fft_db = []\n",
    "while s_start < last_s:\n",
    "    s_end   = min(int( (t_start_s + n_cut*cut_len_s) * sr ), last_s)\n",
    "    x_cut.append(x[s_start:s_end])\n",
    "    x_cut_fft.append(librosa.stft(x_cut[-1], \n",
    "                        n_fft=n_fft, win_length=None, hop_length=None,\n",
    "                        window='hann', center=True, dtype=None, pad_mode='constant'))\n",
    "    x_cut_fft_db.append(librosa.amplitude_to_db(abs(x_cut_fft[-1])))\n",
    "    n_cut  += 1\n",
    "    s_start = s_end + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_cut))\n",
    "print(len(x_cut[-1]))\n",
    "print(len(x_cut_fft))\n",
    "print(len(x_cut_fft[1]))\n",
    "for db in x_cut_fft_db:\n",
    "    fig, ax = plt.subplots(figsize=(15, 6))  \n",
    "    img     = librosa.display.specshow(\n",
    "        db, sr=sr, x_axis='time', y_axis='log', \n",
    "        ax=ax, cmap='magma')\n",
    "    ax.set_title('Spectogram Db', fontsize=14)\n",
    "    #ax.set_ylim(0,26000 )\n",
    "    plt.colorbar(img, ax=ax, format=f'%0.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start_s =      1 * 60\n",
    "t_end_s   =     10 * 60\n",
    "s_start   = int(t_start_s * sr)\n",
    "s_end     = int(  t_end_s * sr)\n",
    "x_cut     = x[s_start:s_end]\n",
    "\n",
    "n_samples      = x_cut.shape[0]\n",
    "zero_crossings = librosa.zero_crossings(x_cut, pad=False)\n",
    "n_zero_cross   = sum(zero_crossings)\n",
    "smpl_per_z_x   = n_samples / n_zero_cross\n",
    "num_zeroes     = n_samples - len(x_cut.nonzero()[0])\n",
    "abs_max        = max(abs(x_cut.max()), abs(x_cut.min()))\n",
    "print(type(x), type(sr))#<class 'numpy.ndarray'> <class 'int'>print(x.shape, sr)#(94316,) 22050\n",
    "print(f\"shape       : {x_cut.shape}\")\n",
    "print(f\"sample rate : {sr}\")\n",
    "print(f\"Size        : {x_cut.nbytes/1000000} Mb\")\n",
    "print(f\"Max Value   : {x_cut.max()}\")\n",
    "print(f\"Min Value   :{x_cut.min()}\")\n",
    "print(f\"Max abs Val : {abs_max}\")\n",
    "print(f\"Number  of  Zeroes crossing: {n_zero_cross} z_Xings\")\n",
    "print(f\"Samples per Zeroes crossing: {smpl_per_z_x:8.2f} smpl/z_Xings\")\n",
    "print(f\"Zeroes crossing rate       : {1/(smpl_per_z_x/sr):7.1f} z_Xings/s\")\n",
    "print(f\"Zeroes      : {num_zeroes}\")\n",
    "print(f\"Zeroes      : {100 * num_zeroes / n_samples:6.2f}%\")\n",
    "print(f\"Mean        : {100 * x_cut.mean()   / (abs_max) :7.3f}%\")\n",
    "#x.cumsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_start    = 0.4  # fraction of the streal where the sample window starts\n",
    "window_siz = 1000  # the number of sample to display\n",
    "n_fft      = 1024\n",
    "n0 = int(p_start * n_samples)\n",
    "n1 = n0 + window_siz\n",
    "plt.figure(figsize=(15, 6))\n",
    "librosa.display.waveshow(x_cut, sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16, 6))\n",
    "# ft = np.abs(librosa.stft(x_cut[:n_fft], hop_length = n_fft+1))\n",
    "# plt.plot(ft);\n",
    "# plt.title('Spectrum');\n",
    "# plt.xlabel('Frequency Bin');\n",
    "# plt.ylabel('Amplitude');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fft      = librosa.stft(x_cut, n_fft=n_fft, win_length=n_fft)\n",
    "x_fft_db   = librosa.amplitude_to_db(abs(x_fft))\n",
    "#x_fft_db_2 = np.square(x_fft_db) \n",
    "print(type(x_fft_db  ))\n",
    "print(x_fft_db.shape  )\n",
    "print(type(x_fft_db_2.shape))\n",
    "print(x_fft_db_2.shape  )\n",
    "x\n",
    "abs_max        = max(abs(x_fft_db_2.max()), abs(x_fft_db_2.min()))\n",
    "print(type(x), type(sr))#<class 'numpy.ndarray'> <class 'int'>print(x.shape, sr)#(94316,) 22050\n",
    "print(f\"shape       : {x_fft_db_2.shape}\")\n",
    "print(f\"Size        : {x_fft_db_2.nbytes/1000000} Mb\")\n",
    "print(f\"Max Value   : {x_fft_db_2.max()}\")\n",
    "print(f\"Min Value   :{x_fft_db_2.min()}\")\n",
    "print(f\"Max abs Val : {abs_max}\")\n",
    "print(f\"Mean        : {100 * x_fft_db_2.mean()   / (abs_max) :7.3f}%\")\n",
    "#x.cumsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16, 6))\n",
    "# plt.plot(x_fft_db);\n",
    "# plt.title('Spectrum');\n",
    "# plt.xlabel('Frequency Bin');\n",
    "# plt.ylabel('Amplitude');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6))  \n",
    "img     = librosa.display.specshow(\n",
    "    x_fft_db, sr=sr, x_axis='time', y_axis='log', \n",
    "    ax=ax, cmap='magma')\n",
    "ax.set_title('Spectogram Db', fontsize=14)\n",
    "#ax.set_ylim(0,26000 )\n",
    "plt.colorbar(img, ax=ax, format=f'%0.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 6))  \n",
    "img     = librosa.display.specshow(x_fft_db_2, sr=sr, x_axis='time', y_axis='hz')\n",
    "ax.set_title('Spectogram intensity', fontsize=14)\n",
    "ax.set_ylim(0,30000 )\n",
    "plt.colorbar(img, ax=ax, format=f'%0.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel     = librosa.feature.melspectrogram(y=x_cut, sr=sr, n_mels=256)\n",
    "mel_db  = librosa.amplitude_to_db(mel, ref=np.max)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 6))  \n",
    "img     = librosa.display.specshow(mel_db, x_axis='time', y_axis='log', ax=ax)\n",
    "ax.set_title('Mel Spectogram', fontsize=14)\n",
    "fig.colorbar(img, ax=ax, format=f'%0.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_fmt    = librosa.fmt(x, t_min=0.5, n_fmt=None, kind='cubic', beta=0.5, over_sample=1, axis=-1)\n",
    "#x_fmt_db = librosa.amplitude_to_db(abs(x_fmt))\n",
    "x_hcqt    = librosa.hybrid_cqt(x_cut)\n",
    "x_hcqt_db = librosa.amplitude_to_db(abs(x_hcqt))\n",
    "fig, ax = plt.subplots(figsize=(15, 6))  \n",
    "img     = librosa.display.specshow(x_hcqt_db, sr=sr, x_axis='time', y_axis='hz')\n",
    "ax.set_title('Compute the hybrid constant-Q transform', fontsize=14)\n",
    "#ax.set_ylim(0,13000 )\n",
    "plt.colorbar(img, ax=ax, format=f'%0.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_iirt    = librosa.iirt(x_cut)\n",
    "x_iirt_db = librosa.amplitude_to_db(abs(x_iirt))\n",
    "fig, ax = plt.subplots(figsize=(15, 6))  \n",
    "img     = librosa.display.specshow(x_iirt_db, sr=sr, x_axis='time', y_axis='hz')\n",
    "ax.set_title('Time-frequency representation using IIR filters', fontsize=14)\n",
    "#ax.set_ylim(0,13000 )\n",
    "plt.colorbar(img, ax=ax, format=f'%0.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_length = 256\n",
    "\n",
    "chromagram = librosa.feature.chroma_stft(x_cut, sr=sr, hop_length=hop_length)\n",
    "fig, ax    = plt.subplots(figsize=(15, 6))  \n",
    "img        = librosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', hop_length=hop_length, cmap='coolwarm')\n",
    "ax.set_title('Chroma SFT', fontsize=14)\n",
    "#ax.set_ylim(0,13000 )\n",
    "plt.colorbar(img, ax=ax, format=f'%0.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = librosa.feature.mfcc(x_cut, sr=sr)\n",
    "print(mfccs.shape)\n",
    "#(20, 97)\n",
    "#Displaying  the MFCCs:\n",
    "fig, ax    = plt.subplots(figsize=(15, 6))  \n",
    "img        = librosa.display.specshow(mfccs, sr=sr, x_axis='time')\n",
    "ax.set_title('MFCC', fontsize=14)\n",
    "#ax.set_ylim(0,13000 )\n",
    "plt.colorbar(img, ax=ax, format=f'%0.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_centroids = librosa.feature.spectral_centroid(x_cut, sr=sr)[0]\n",
    "spectral_centroids.shape\n",
    "(775,)\n",
    "# Computing the time variable for visualization\n",
    "plt.figure(figsize=(12, 4))\n",
    "frames = range(len(spectral_centroids))\n",
    "t = librosa.frames_to_time(frames)\n",
    "# Normalising the spectral centroid for visualisation\n",
    "def normalize(x_cut, axis=0):\n",
    "    return sklearn.preprocessing.minmax_scale(x_cut, axis=axis)\n",
    "#Plotting the Spectral Centroid along the waveform\n",
    "librosa.display.waveshow(x_cut, sr=sr, alpha=0.4)\n",
    "plt.plot(t, normalize(spectral_centroids), color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "spectral_rolloff = librosa.feature.spectral_rolloff(x_cut+0.01, sr=sr)[0]\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.waveshow(x_cut, sr=sr, alpha=0.4)\n",
    "plt.plot(t, normalize(spectral_rolloff), color='r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spectral_bandwidth_2 = librosa.feature.spectral_bandwidth(x_cut+0.01, sr=sr)[0]\n",
    "spectral_bandwidth_3 = librosa.feature.spectral_bandwidth(x_cut+0.01, sr=sr, p=3)[0]\n",
    "spectral_bandwidth_4 = librosa.feature.spectral_bandwidth(x_cut+0.01, sr=sr, p=4)[0]\n",
    "plt.figure(figsize=(15, 9))\n",
    "librosa.display.waveshow(x_cut, sr=sr, alpha=0.4)\n",
    "plt.plot(t, normalize(spectral_bandwidth_2), color='r')\n",
    "plt.plot(t, normalize(spectral_bandwidth_3), color='g')\n",
    "plt.plot(t, normalize(spectral_bandwidth_4), color='y')\n",
    "plt.legend(('p = 2', 'p = 3', 'p = 4'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SPAA_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46c0c59ec8d812952b3a4b632d9b0103b74b437132d068b7804dfb4d8ba16faa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
